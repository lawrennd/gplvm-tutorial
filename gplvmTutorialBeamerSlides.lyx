#LyX 1.3 created this file. For more info see http://www.lyx.org/
\lyxformat 221
\textclass beamer
\begin_preamble
\usepackage{listings}
\usetheme{Warsaw}
\setbeamercovered{transparent}
\usepackage{ae,aecompl}


\newcommand{\citet}[1]{\cite{#1}}
\end_preamble
\options 20pt,dvips
\language english
\inputencoding auto
\fontscheme default
\graphics default
\paperfontsize default
\spacing single 
\papersize Custom
\paperpackage a4
\use_geometry 1
\use_amsmath 1
\use_natbib 0
\use_numerical_citations 1
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\quotes_times 2
\papercolumns 1
\papersides 1
\paperpagestyle default
\bullet 0
	2
	20
	-1
\end_bullet
\bullet 1
	5
	4
	-1
\end_bullet

\layout Left Header

Neil Lawrence
\layout Right Header

The Gaussian Process Latent Variable Model
\layout My Logo


\begin_inset Graphics
	filename ./diagrams/sheffieldlogo.pdf
	lyxscale 40
	scale 25

\end_inset 


\layout Right Footer


\begin_inset Graphics
	filename ./diagrams/dcslogo.pdf
	lyxscale 120

\end_inset 


\begin_inset ERT
status Collapsed

\layout Standard

\backslash 
quad 
\end_inset 


\family sans 

\begin_inset ERT
status Collapsed

\layout Standard

\backslash 
thepage{}
\end_inset 


\layout Title

The Gaussian Process Latent Variable Model
\layout Date

27th January 2006
\layout Author

Neil D.
 Lawrence
\layout Address
\align center 

\size large 
Oxford
\layout EndFrame

\layout BeginFrame

Introduction
\layout Itemize

The Gaussian process latent variable model (GP-LVM)
\begin_deeper 
\layout Itemize

powerful approach to probabilistic non-linear dimensionality reduction.
\end_deeper 
\layout Itemize

This review:
\begin_deeper 
\layout Itemize

Review Probabilistic PCA 
\begin_inset LatexCommand \citep{Tipping:probpca99}

\end_inset 

.
 
\layout Itemize

Review Gaussian Processes.
\layout Itemize

Derive GP-LVM.
\layout Itemize

Present some Results.
\layout Standard

Examples that can be recreated: code from 
\begin_inset LatexCommand \\htmlurl{http://www.dcs.shef.ac.uk/~neil/fgplvm}

\end_inset 

 & 
\begin_inset LatexCommand \\htmlurl{http://www.dcs.shef.ac.uk/~neil/oxford}

\end_inset 

.
\end_deeper 
\layout EndFrame

\layout BeginFrame

Motivation
\layout Itemize

Many data sets are high dimensional.
 
\layout Itemize

`Curse of dimensionality' implies that we need many data points.
\layout Itemize

In practice we often do very well with smaller data sets.
 
\layout Itemize

Perhaps many data sets of interest seem high dimensional but are intrinsically
 low dimensional.
\layout EndFrame

\layout BeginFrame

Digits Data
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./diagrams/digitSix.pdf
	lyxscale 50
	width 50text%

\end_inset 


\layout Standard


\begin_inset ERT
status Collapsed

\layout Standard

\backslash 
small 
\end_inset 


\layout Caption

Digit 6 from the USPS Cedar CD-ROM.
 The digit is 64 pixels by 57 pixels giving it 3,648 dimensions.
 
\begin_inset LatexCommand \label{cap:digit6}

\end_inset 


\end_inset 


\layout EndFrame

\layout BeginFrame

Lower Intrinsic Dimensionality
\layout Itemize

This data point is 3,648 dimensional.
 
\layout Itemize

Data won't span all 3,648 dimensions of the space.
 
\layout Itemize

Consider digit rotations.
\layout Itemize

Let's consider rotations of the digit:
\begin_deeper 
\layout Itemize

Create a data set by rotating the original digit 360 times.
 
\layout Itemize

Project data onto its 2nd & 3rd principal components.
\end_deeper 
\layout EndFrame

\layout BeginFrame

Rotated Digit
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./diagrams/demManifoldPrint1.pdf
	lyxscale 50
	width 45text%

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/demManifoldPrint2.pdf
	lyxscale 50
	width 45text%

\end_inset 


\layout Caption

Rotation of handwritten 6.
 Data set generated by rotating the original image 360 times .
\begin_inset LatexCommand \label{cap:twoManifolds}

\end_inset 


\end_inset 


\layout EndFrame

\layout BeginFrame

More Transformations
\layout Itemize

Real data sets not generated by a simple rotation of a one dimensional space.
 
\layout Itemize

Reasonable to assume a data set:
\begin_deeper 
\layout Itemize

has fixed number of `prototypes' 
\layout Itemize

each undergoes a limited number of transformations 
\layout Itemize

and is, perhaps, corrupted by some noise.
 
\end_deeper 
\layout Itemize

Makes sense to model high dimensional data by seeking a low dimensional
 `embedding'.
\layout EndFrame

\layout BeginFrame

Traditional Approaches
\layout Itemize

Standard approach in statistics: multi-dimensional scaling (MDS, see 
\emph on 
e.g.
 
\emph default 

\begin_inset LatexCommand \citet{Mardia:multivariate79}

\end_inset 

).
 
\layout Itemize

Recently in Machine Learning several spectral approaches.
 (
\begin_inset LatexCommand \citet{Tenenbaum:isomap00,Roweis:lle00,Weinberger:learning04}

\end_inset 

) 
\layout Itemize

Some can be seen as classical MDS.
\layout Itemize

We seek a probabilistic approach:
\begin_deeper 
\layout Itemize

Ease of extension, for the GP-LVM see (
\begin_inset LatexCommand \citet{Grochow:styleik04,Urtasun:priors05,Wang:gpdm05,Shon:learning05}

\end_inset 

).
\end_deeper 
\layout EndFrame

\layout BeginFrame

Coming Up
\layout Itemize

Review of Probabilistic PCA.
\layout Itemize

Review of Gaussian Processes.
\layout Itemize

Dual Probabilistic PCA and the GP-LVM.
\layout Itemize

Results from the GP-LVM + back constraints, dynamics etc.
\layout EndFrame

\layout BeginFrame

Probabilistic PCA
\begin_inset LatexCommand \label{sec:PPCA}

\end_inset 


\layout Itemize

Given points in a latent space 
\begin_inset Formula $\mathbf{X}=\left[\mathbf{x}_{1},\dots,\mathbf{x}_{N}\right]^{\textrm{T}}$
\end_inset 

 and a 
\emph on 
centred data set
\emph default 
, 
\begin_inset Formula $\mathbf{Y}=\left[\mathbf{y}_{1},\dots,\mathbf{y}_{N}\right]^{\textrm{T}}$
\end_inset 

 assume
\begin_inset Formula \[
\mathbf{y}_{n}=\mathbf{W}\mathbf{x}_{n}+\boldsymbol{\eta}_{n},\]

\end_inset 


\begin_inset Formula $\mathbf{W}\in\Re^{D\times q}$
\end_inset 

 , 
\begin_inset Formula $D$
\end_inset 

 -- data space dim, 
\begin_inset Formula $q$
\end_inset 

 -- latent space dim., 
\begin_inset Formula $\boldsymbol{\eta}_{n}$
\end_inset 

 noise term.
\layout Itemize

For probabilistic PCA, 
\begin_inset Formula \[
p\left(\boldsymbol{\eta}_{n}|\beta\right)=N\left(\boldsymbol{\eta}_{n}|\mathbf{0},\beta^{-1}\mathbf{I}\right),\]

\end_inset 

 
\begin_inset Formula $\beta$
\end_inset 

 is an inverse variance or precision.
\layout EndFrame

\layout BeginFrame

Probabilistic PCA contd
\layout Itemize

Conditional probability of the data given the latent space written as
\begin_inset Formula \[
p\left(\mathbf{y}_{n}|\mathbf{x}_{n},\mathbf{W},\beta\right)=N\left(\mathbf{y}_{n}|\mathbf{W}\mathbf{x}_{n},\beta^{-1}\mathbf{I}\right),\]

\end_inset 

assume independence across data points 
\begin_inset Formula \begin{equation}
p\left(\mathbf{Y}|\mathbf{X},\mathbf{W},\beta\right)=\prod_{n=1}^{N}N\left(\mathbf{y}_{n}|\mathbf{W}\mathbf{x}_{n},\beta^{-1}\mathbf{I}\right).\label{eq:ppcaLikelihood}\end{equation}

\end_inset 

This term can be seen as a 
\emph on 
likelihood
\emph default 
.
 
\layout EndFrame

\layout BeginFrame

Gaussian Prior
\layout Itemize

The Gaussian prior over 
\begin_inset Formula $\mathbf{X}$
\end_inset 

 is zero mean and unit covariance,
\begin_inset Formula \begin{equation}
p\left(\mathbf{X}\right)=\prod_{n=1}^{N}p\left(\mathbf{x}_{n}\right)=\prod_{n=1}^{N}N\left(\mathbf{x}_{n}|\mathbf{0},\mathbf{I}\right).\label{eq:ppcaPrior}\end{equation}

\end_inset 


\layout Itemize

The marginal likelihood is then,
\begin_inset Formula \begin{equation}
p\left(\mathbf{Y}|\mathbf{W},\beta\right)=\prod_{n=1}^{N}N\left(\mathbf{y}_{n}|\mathbf{0},\mathbf{C}\right),\label{eq:ppcaMarginaLikelihood}\end{equation}

\end_inset 

where 
\begin_inset Formula $\mathbf{C}=\mathbf{WW}^{\textrm{T}}+\beta^{-1}\mathbf{I}$
\end_inset 

.
 
\layout EndFrame

\layout BeginFrame

Reduced Rank Covariance
\layout Itemize


\begin_inset Formula $\mathbf{C}$
\end_inset 

 is recognised as a reduced rank representation of the covariance.
 
\begin_inset Formula \[
\mathbf{C}=\mathbf{WW}^{\textrm{T}}+\beta^{-1}\mathbf{I}\]

\end_inset 

 
\layout Itemize

Since 
\begin_inset Formula $\mathbf{W}\in\Re^{D\times q}$
\end_inset 

 the matrix 
\begin_inset Formula $\mathbf{W}\mathbf{W}^{\textrm{T}}\in\Re^{D\times D}$
\end_inset 

 will have rank of at most 
\begin_inset Formula $q$
\end_inset 

.
 
\layout Itemize

The term 
\begin_inset Formula $\beta^{-1}\mathbf{I}$
\end_inset 

 then acts as a `regulariser'.
\layout EndFrame

\layout BeginFrame

Maximum Likelihood Solution
\layout Itemize

Model was suggested simultaneously by 
\begin_inset LatexCommand \citet{Roweis:SPCA97,Tipping:probpca99}

\end_inset 

.
 
\layout Itemize

But 
\begin_inset LatexCommand \citet{Tipping:probpca99}

\end_inset 

 also proved that maximum likelihood solution for 
\begin_inset Formula $\mathbf{W}$
\end_inset 

 spans the principal sub-space.
 
\layout Itemize

Solution is 
\begin_inset Formula \[
\hat{\mathbf{W}}=\mathbf{U}_{q}^{\prime}\mathbf{L}\mathbf{V}^{\textrm{T}}\]

\end_inset 


\begin_inset Formula $\mathbf{U}_{q}^{\prime}$
\end_inset 

 are 
\begin_inset Formula $q$
\end_inset 

 eigenvectors of 
\begin_inset Formula $N^{-1}\mathbf{Y}^{\textrm{T}}\mathbf{Y}$
\end_inset 

 associated with 
\begin_inset Formula $q$
\end_inset 

 largest eigenvalues, 
\begin_inset Formula $\left\{ \lambda_{i}\right\} _{i=1}^{q}$
\end_inset 

 .
\layout Itemize


\begin_inset Formula $\mathbf{L}$
\end_inset 

 is diagonal, its 
\begin_inset Formula $i$
\end_inset 

th element is 
\begin_inset Formula $l_{i}=\left(\lambda_{i}-\beta^{-1}\right)^{\frac{1}{2}}$
\end_inset 

.
 
\layout EndFrame

\layout BeginFrame

Eigenvalue Problem
\layout Itemize


\emph on 
I.e.

\emph default 
 we solve this eigenvalue problem
\begin_inset Formula \begin{equation}
N^{-1}\mathbf{Y}^{\textrm{T}}\mathbf{YU}^{\prime}=\mathbf{U}^{\prime}\Lambda.\label{eq:ppcaEigenValueProblem}\end{equation}

\end_inset 

 
\layout Itemize

Solution for probabilistic PCA spans the 
\begin_inset Formula $q$
\end_inset 

-dimensional principal sub-space of the data.
 
\layout EndFrame

\layout BeginFrame

Gaussian Processes
\begin_inset LatexCommand \label{sec:GPs}

\end_inset 


\layout Itemize

Gaussian processes: 
\begin_inset LatexCommand \citep{Ohagan:curve78,Ohagan:numerical92,Williams:Gaussian96,Williams:prediction98,MacKay:gpintroduction98,Rasmussen:book06}

\end_inset 

, probability distributions over functions.
\layout Itemize

Functions are infinite dimensional objects.
\layout Itemize

Consider a finite Gaussian distribution over instantiated values 
\begin_inset Formula $\mathbf{f}=\left\{ f_{n}\right\} _{n=1}^{N}\in\Re^{N\times1}$
\end_inset 

.
 
\layout Itemize

Assume that these values are drawn from a Gaussian distribution.
\layout EndFrame

\layout BeginFrame

Gaussian Processes
\layout Itemize

Typically assume mean zero and covariance 
\begin_inset Formula $\mathbf{K}$
\end_inset 

,
\begin_inset Formula \begin{eqnarray*}
p\left(\mathbf{f}|\mathbf{K}\right) & = & N\left(\mathbf{f}|\mathbf{0},\mathbf{K}\right)\\
 & = & \frac{1}{\left(2\pi\right)^{\frac{N}{2}}\left|\mathbf{K}\right|^{\frac{1}{2}}}\exp\left(-\frac{1}{2}\mathbf{f}\mathbf{K}^{-1}\mathbf{f}\right).\end{eqnarray*}

\end_inset 


\layout Itemize

In the next slide, take 
\emph on 
one sample
\emph default 
 from a Gaussian with this covariance matrix.
 
\layout Itemize

In this sample there will be 
\begin_inset Formula $N=25$
\end_inset 

 instantiations.
 
\layout EndFrame

\layout BeginFrame

GP Sample
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard


\begin_inset Graphics
	filename ./diagrams/gpSample.pdf
	lyxscale 50
	width 45text%
	subcaption

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/gpCovariance.pdf
	lyxscale 50
	width 45text%
	subcaption

\end_inset 


\layout Caption

(a) 25 instantiations of a function, 
\begin_inset Formula $f_{n}$
\end_inset 

, (b) covariance matrix as a greyscale plot.
 
\begin_inset LatexCommand \label{cap:demGPSample}

\end_inset 


\end_inset 


\layout EndFrame

\layout BeginFrame

GP Sample
\layout Itemize

Covariance function shows correlation between points 
\begin_inset Formula $f_{m}$
\end_inset 

 and 
\begin_inset Formula $f_{n}$
\end_inset 

 if 
\begin_inset Formula $n$
\end_inset 

 is near to 
\begin_inset Formula $m$
\end_inset 

.
 
\layout Itemize

Less correlation if 
\begin_inset Formula $n$
\end_inset 

 is distant from 
\begin_inset Formula $m$
\end_inset 

.
 
\layout Itemize

The function therefore appears smooth.
\layout Itemize

Let's make predictions given the covariance and 1 data point.
\layout EndFrame

\layout BeginFrame

Point Prediction 1 - 2
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./diagrams/demGPCov2D1_2_1.pdf
	lyxscale 30
	width 30text%

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/demGPCov2D1_2_2.pdf
	lyxscale 30
	width 30text%

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/demGPCov2D1_2_3.pdf
	lyxscale 30
	width 30text%

\end_inset 


\layout Caption

Joint distribution between the values of 
\begin_inset Formula $f_{1}$
\end_inset 

 and 
\begin_inset Formula $f_{2}$
\end_inset 

 , 
\begin_inset Formula $\mathbf{K}_{12}=\left[\begin{array}{cc}
1 & 0.966\\
0.966 & 1\end{array}\right]$
\end_inset 

.
\begin_inset LatexCommand \label{cap:joint12}

\end_inset 


\end_inset 


\layout EndFrame

\layout BeginFrame

Point Prediction 1 - 5
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./diagrams/demGPCov2D1_5_1.pdf
	lyxscale 30
	width 30text%

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/demGPCov2D1_5_2.pdf
	lyxscale 30
	width 30text%

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/demGPCov2D1_5_3.pdf
	lyxscale 30
	width 30text%

\end_inset 


\layout Caption

Joint distribution between the values of 
\begin_inset Formula $f_{1}$
\end_inset 

 and 
\begin_inset Formula $f_{5}$
\end_inset 

, 
\begin_inset Formula $\mathbf{K}_{15}=\left[\begin{array}{cc}
1 & 0.574\\
0.574 & 1\end{array}\right]$
\end_inset 

.
\begin_inset LatexCommand \label{cap:joint15}

\end_inset 


\end_inset 


\layout EndFrame

\layout BeginFrame

Whence Covariance?
\layout Itemize

Covariance matrix is built using the inputs to the function 
\begin_inset Formula $\mathbf{x}_{n}$
\end_inset 

.
 
\layout Itemize

Based on Euclidean distance 
\begin_inset Formula \begin{equation}
k\left(\mathbf{x}_{m},\mathbf{x}_{n}\right)=\exp\left(-\frac{\gamma}{2}\left(\mathbf{x}_{m}-\mathbf{x}_{n}\right)^{\textrm{T}}\left(\mathbf{x}_{m}-\mathbf{x}_{n}\right)\right),\label{eq:rbfOne}\end{equation}

\end_inset 


\layout Itemize

Also known as a kernel.
\layout EndFrame

\layout BeginFrame

Joint Distribution
\layout Itemize

Covariance function provides the joint distribution over the instantiations.
\layout Itemize

Conditional distribution provides predictions.
\layout Itemize

Denote the training set as 
\begin_inset Formula $\mathbf{f}$
\end_inset 

 and test set as 
\begin_inset Formula $\mathbf{f}_{*}$
\end_inset 

, predict using 
\begin_inset Formula $p\left(\mathbf{f}_{*}|\mathbf{f}\right)$
\end_inset 

.
 
\layout Itemize

Find conditional from joint using partiitoned inverse
\begin_inset Formula \[
\mathbf{K}=\left[\begin{array}{cc}
\mathbf{K}_{\mathbf{f},\mathbf{f}} & \mathbf{K}_{\mathbf{f},*}\\
\mathbf{K}_{*,\mathbf{f}} & \mathbf{K}_{*,*}\end{array}\right]\]

\end_inset 


\layout EndFrame

\layout BeginFrame

Partitioned Inverse
\layout Itemize

Partitioned inverse is then
\begin_inset Formula \[
\mathbf{K}^{-1}=\left[\begin{array}{cc}
\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}+\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\mathbf{K}_{\mathbf{f},*}\Sigma^{-1}\mathbf{K}_{*,\mathbf{f}}\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1} & -\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\mathbf{K}_{\mathbf{f},*}\Sigma^{-1}\\
-\Sigma^{-1}\mathbf{K}_{*,\mathbf{f}}\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1} & \mathbf{\Sigma^{-1}}\end{array}\right]\]

\end_inset 

where
\begin_inset Formula \[
\Sigma=\mathbf{K}_{*,*}-\mathbf{K}_{*,\mathbf{f}}\mathbf{K_{\mathbf{f},\mathbf{f}}^{-1}}\mathbf{K}_{\mathbf{f},*}.\]

\end_inset 


\layout EndFrame

\layout BeginFrame

Joint Distribution
\layout Itemize

Logarithm of the joint distribution:
\begin_inset Formula \begin{eqnarray*}
\log p\left(\mathbf{f},\mathbf{f}_{*}\right) & = & -\frac{1}{2}\mathbf{f}^{\textrm{T}}\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\mathbf{f}-\frac{1}{2}\mathbf{f}^{\textrm{T}}\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\mathbf{K}_{\mathbf{f},*}\Sigma^{-1}\mathbf{K}_{*,\mathbf{f}}\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\mathbf{f}\\
 &  & +\mathbf{f}\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\mathbf{K}_{\mathbf{f},*}\Sigma^{-1}\mathbf{f}_{*}-\frac{1}{2}\mathbf{f}_{*}^{\textrm{T}}\Sigma^{-1}\mathbf{f}_{*}+\textrm{const}_{1}\end{eqnarray*}

\end_inset 


\layout Itemize

Conditional is found by dividing joint by the prior, 
\begin_inset Formula $p\left(\mathbf{f}\right)=N\left(\mathbf{f}|\mathbf{0},\mathbf{K}_{\mathbf{f},\mathbf{f}}\right)$
\end_inset 

.
 
\layout EndFrame

\layout BeginFrame

Conditional Distribution
\layout Itemize

In log space this is equivalent to subtraction of 
\begin_inset Formula \[
\log p\left(\mathbf{f}\right)=\mathbf{-}\frac{1}{2}\mathbf{f}^{\textrm{T}}\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\mathbf{f}+\textrm{const}_{2}\]

\end_inset 

giving 
\begin_inset Formula \begin{eqnarray*}
\log p\left(\mathbf{f}_{*}|\mathbf{f}\right) & = & \log p\left(\mathbf{f}_{*},\mathbf{f}\right)-\log p\left(\mathbf{f}\right)=\log N\left(\mathbf{f}_{*}|\mathbf{\bar{\mathbf{f}}}_{*},\Sigma\right).\end{eqnarray*}

\end_inset 

where 
\begin_inset Formula $\bar{\mathbf{f}}=\mathbf{K}_{*,\mathbf{f}}\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\mathbf{f}$
\end_inset 

 and 
\begin_inset Formula $\Sigma=\mathbf{K}_{*,*}-\mathbf{K}_{*,\mathbf{f}}\mathbf{K_{\mathbf{f},\mathbf{f}}^{-1}}\mathbf{K}_{\mathbf{f},*}.$
\end_inset 


\layout EndFrame

\layout BeginFrame

Prediction
\layout Itemize

If we observe points from the function, 
\series bold 

\begin_inset Formula $\mathbf{f}$
\end_inset 

.

\series default 
 
\layout Itemize

We can predict the locations of functions at as yet unseen locations.
 
\layout Itemize

The prediction is also a Gaussian process, with mean 
\begin_inset Formula $\bar{\mathbf{f}}$
\end_inset 

 and covariance 
\begin_inset Formula $\Sigma$
\end_inset 

.
 
\layout Itemize

Often observe corrupted version of function.
\layout EndFrame

\layout BeginFrame

GP Graphical Model
\begin_inset Note
collapsed false

\layout Standard

Now, if we wish to make inferences about the function at other locations
 we can do so through Bayes' rule,
\begin_inset Formula \[
p\left(\mathbf{f}_{*}|\mathbf{y}\right)=\int p\left(\mathbf{f}_{*}|\mathbf{f}\right)p\left(\mathbf{f}|\mathbf{y}\right)d\mathbf{f}\]

\end_inset 

for which we first need the posterior over 
\begin_inset Formula $\mathbf{f}$
\end_inset 

 given the observations,
\begin_inset Formula \[
p\left(\mathbf{f}|\mathbf{y}\right)\propto p\left(\mathbf{y}|\mathbf{f}\right)p\left(\mathbf{f}\right)\]

\end_inset 

This can be computed as
\begin_inset Formula \begin{eqnarray*}
\log p\left(\mathbf{f}|\mathbf{y}\right) & = & \log p\left(\mathbf{y}|\mathbf{f}\right)+\log p\left(\mathbf{f}\right)\\
 & = & -\frac{\beta}{2}\left(\mathbf{y}-\mathbf{f}\right)^{\textrm{T}}\left(\mathbf{y}-\mathbf{f}\right)-\frac{1}{2}\mathbf{f}^{\textrm{T}}\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\mathbf{f}+\textrm{const}_{4}\\
 & = & -\frac{1}{2}\mathbf{f}^{\textrm{T}}\left(\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}+\beta\mathbf{I}\right)\mathbf{f}+\beta\mathbf{y}^{\textrm{T}}\mathbf{f}+\textrm{const}_{5}\\
 & = & -\left(\mathbf{f}-\mathbf{A}^{-1}\beta\mathbf{y}\right)^{\textrm{T}}\mathbf{A}\left(\mathbf{f}-\mathbf{A}^{-1}\beta\mathbf{y}\right)+\textrm{const _{6}}\\
 & = & \log N\left(\mathbf{f}|\mathbf{A}^{-1}\beta\mathbf{y},\mathbf{A}^{-1}\right),\end{eqnarray*}

\end_inset 

where 
\begin_inset Formula $\mathbf{A}=\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}+\beta\mathbf{I}$
\end_inset 

.
 So we see that the posterior process for 
\begin_inset Formula $\mathbf{f}$
\end_inset 

 is a Gaussian process with mean 
\begin_inset Formula $\mathbf{A}^{-1}\beta\mathbf{y}$
\end_inset 

 and covariance 
\begin_inset Formula $\mathbf{A}^{-1}$
\end_inset 

.
 This can be combined with the conditional distribution () to give
\begin_inset Formula \begin{eqnarray*}
p\left(\mathbf{f}_{*}|\mathbf{y}\right) & = & \int p\left(\mathbf{f}_{*}|\mathbf{f}\right)p\left(\mathbf{f}|\mathbf{y}\right)d\mathbf{f}\\
 & = & \int N\left(\mathbf{f}_{*}|\mathbf{K}_{\mathbf{f},*}\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\mathbf{f},\Sigma\right)N\left(\mathbf{f}|\mathbf{A}^{-1}\beta\mathbf{y},\mathbf{A}^{-1}\right)d\mathbf{f}\\
 & \propto & \int\exp\left(-\frac{1}{2}\left(\mathbf{f}_{*}-\mathbf{K}_{*,\mathbf{f}}\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\mathbf{f}\right)^{\textrm{T}}\Sigma^{-1}\left(\mathbf{f}_{*}-\mathbf{K}_{*,\mathbf{f}}\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\mathbf{f}\right)-\frac{1}{2}\left(\mathbf{f}-\mathbf{A}^{-1}\beta\mathbf{y}\right)^{\textrm{T}}\mathbf{A}\left(\mathbf{f}-\mathbf{A}^{-1}\beta\mathbf{y}\right)\right)d\mathbf{f}\\
 & \propto & \int\exp\left(-\frac{1}{2}\mathbf{f}^{\textrm{T}}\left(\mathbf{A}+\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\mathbf{K}_{\mathbf{f},*}\Sigma^{-1}\mathbf{K}_{*,\mathbf{f}}\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\right)\mathbf{f}+\left(\mathbf{f}_{*}^{\textrm{T}}\Sigma^{-1}\mathbf{K}_{*,\mathbf{f}}\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}+\beta\mathbf{y}^{\textrm{T}}\right)\mathbf{f}-\frac{1}{2}\mathbf{f}_{*}^{\textrm{T}}\Sigma^{-1}\mathbf{f}_{*}-\frac{\beta^{2}}{2}\mathbf{y}^{\textrm{T}}\mathbf{A}^{-1}\mathbf{y}\right)d\mathbf{f}\\
 & \propto & \exp\left(-\frac{1}{2}\mathbf{f}_{*}^{\textrm{T}}\Sigma^{-1}\mathbf{f}_{*}+\left(\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\mathbf{K}_{\mathbf{f},*}\Sigma^{-1}\mathbf{f}_{*}+\beta\mathbf{y}\right)\left(\mathbf{A}+\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\mathbf{K}_{\mathbf{f},*}\Sigma^{-1}\mathbf{K}_{*,\mathbf{f}}\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\right)\left(\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\mathbf{K}_{\mathbf{f},*}\Sigma^{-1}\mathbf{f}_{*}+\beta\mathbf{y}\right)\right)\\
 & \propto & \exp\left(-\frac{1}{2}\mathbf{f}_{*}^{\textrm{T}}\left(\Sigma^{-1}-\Sigma^{-1}\mathbf{K}_{*,\mathbf{f}}\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\left(\mathbf{A}+\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\mathbf{K}_{\mathbf{f},*}\Sigma^{-1}\mathbf{K}_{*,\mathbf{f}}\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\right)\mathbf{K}_{\mathbf{f},\mathbf{f}}^{-1}\mathbf{K}_{\mathbf{f},*}\Sigma^{-1}\right)\mathbf{f}_{*}\right)\end{eqnarray*}

\end_inset 


\layout Standard

for which we require the marginal likelihood, 
\begin_inset Formula $p\left(\mathbf{y}\right)$
\end_inset 

.
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./diagrams/gpGraph.pdf
	width 35text%

\end_inset 


\layout Caption

The Gaussian process depicted graphically, here 
\begin_inset Formula $\theta$
\end_inset 

 represents model parameters.
\begin_inset LatexCommand \label{cap:gpGraph}

\end_inset 


\end_inset 


\layout EndFrame

\layout BeginFrame

Noise Model
\layout Itemize

Observations are corrupted by noise.
 
\layout Itemize

Define a noise model 
\begin_inset Formula $p\left(\mathbf{y}|\mathbf{f}\right)$
\end_inset 

 
\layout Itemize

In regression
\begin_inset Formula \begin{equation}
p\left(\mathbf{y}|\mathbf{f}\right)=\prod_{n=1}^{N}p\left(y_{n}|f_{n}\right)=\prod_{n=1}^{N}N\left(y_{n}|f_{n},\beta^{-1}\right),\label{eq:gpGaussNoise}\end{equation}

\end_inset 


\layout EndFrame

\layout BeginFrame

Marginal Likelihood
\layout Itemize

Maximise marginal likelihood,
\begin_inset Formula \[
p\left(\mathbf{y}\right)=\int p\left(\mathbf{y}|\mathbf{f}\right)p\left(\mathbf{f}\right)d\mathbf{f},\]

\end_inset 


\begin_inset Formula \begin{eqnarray}
p\left(\mathbf{y}\right) & = & N\left(\mathbf{y}|\mathbf{0},\mathbf{K}_{\mathbf{f},\mathbf{f}}+\beta^{-1}\mathbf{I}\right),\label{eq:gaussianMarginal}\end{eqnarray}

\end_inset 

Result is a Gaussian process on 
\begin_inset Formula $\mathbf{y}$
\end_inset 

 with covariance 
\begin_inset Formula $\mathbf{K}_{\mathbf{f},\mathbf{f}}+\beta^{-1}\mathbf{I}$
\end_inset 

.
 
\layout EndFrame

\layout BeginFrame

Covariance Functions
\layout Itemize

RBF Covariance has two parameters:
\begin_inset Formula \begin{equation}
k\left(\mathbf{x}_{m},\mathbf{x}_{n}\right)=\alpha\exp\left(-\frac{\gamma}{2}\left(\mathbf{x}_{m}-\mathbf{x}_{n}\right)^{\textrm{T}}\left(\mathbf{x}_{m}-\mathbf{x}_{n}\right)\right),\label{eq:rbfTwo}\end{equation}

\end_inset 

control signal and and length scale
\layout Itemize

Linear Covariance Function 
\begin_inset Formula \[
k\left(\mathbf{x}_{m},\mathbf{x}_{n}\right)=\alpha\mathbf{x}_{m}^{\textrm{T}}\mathbf{x}_{n}\]

\end_inset 


\begin_inset Formula \[
\mathbf{K}_{\mathbf{f},\mathbf{f}}=\mathbf{X}\mathbf{X}^{\textrm{T}}\]

\end_inset 

 
\layout EndFrame

\layout BeginFrame

Different Covariance Functions
\begin_inset LatexCommand \label{sub:covarianceFunctions}

\end_inset 


\layout Itemize

Multi-layer perceptron covariance 
\begin_inset LatexCommand \citet{Williams:infinite96}

\end_inset 


\begin_inset Formula \[
k\left(\mathbf{x}_{m},\mathbf{x}_{n}\right)=\alpha\textrm{sin}^{-1}\left(\frac{w\mathbf{x}_{m}^{\textrm{T}}\mathbf{x}_{n}+b}{\sqrt{w\mathbf{x}_{m}^{\textrm{T}}\mathbf{x}_{m}+b+1}\sqrt{w\mathbf{x}_{n}^{\textrm{T}}\mathbf{x}_{n}+b+1}}\right),\]

\end_inset 


\layout Itemize

Bias 
\begin_inset Formula \[
k\left(\mathbf{x}_{m},\mathbf{x}_{n}\right)=\alpha,\]

\end_inset 


\layout Itemize

Parameters of the covariance function found through maximisation of marginal
 likelihood.
\layout EndFrame

\layout BeginFrame

Covariance Samples
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard


\begin_inset Graphics
	filename ./diagrams/demCovFuncSample1.pdf
	lyxscale 40
	width 30text%
	subcaption

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/demCovFuncSample2.pdf
	lyxscale 40
	width 30text%
	subcaption

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/demCovFuncSample3.pdf
	lyxscale 40
	width 30text%
	subcaption

\end_inset 


\layout Caption

Samples from different covariance functions.
 (a) RBF kernel with 
\begin_inset Formula $\gamma=10$
\end_inset 

, 
\begin_inset Formula $\alpha=1$
\end_inset 

, (b) RBF kernel with 
\begin_inset Formula $\gamma=1$
\end_inset 

, 
\begin_inset Formula $\alpha=1$
\end_inset 

 (c) RBF kernel with 
\begin_inset Formula $\gamma=10$
\end_inset 

, 
\begin_inset Formula $\alpha=4$
\end_inset 

.
 
\begin_inset LatexCommand \label{cap:kernelSamples}

\end_inset 


\end_inset 


\layout EndFrame

\layout BeginFrame

Covariance Samples
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard


\begin_inset Graphics
	filename ./diagrams/demCovFuncSample4.pdf
	lyxscale 40
	width 30text%
	subcaption

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/demCovFuncSample5.pdf
	lyxscale 40
	width 30text%
	subcaption

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/demCovFuncSample6.pdf
	lyxscale 40
	width 30text%
	subcaption

\end_inset 


\layout Caption

(a) linear kernel with 
\begin_inset Formula $\alpha=16$
\end_inset 

, (b) MLP kernel with 
\begin_inset Formula $\alpha=8$
\end_inset 

, 
\begin_inset Formula $w=100$
\end_inset 

 and 
\begin_inset Formula $b=100$
\end_inset 

, (c) MLP kernel with 
\begin_inset Formula $\alpha=8$
\end_inset 

, 
\begin_inset Formula $b=0$
\end_inset 

 and 
\begin_inset Formula $w=100$
\end_inset 

.
\begin_inset LatexCommand \label{cap:kernelSamples}

\end_inset 


\end_inset 


\layout EndFrame

\layout BeginFrame

Covariance Samples
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard


\begin_inset Graphics
	filename ./diagrams/demCovFuncSample7.pdf
	lyxscale 40
	width 30text%
	subcaption

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/demCovFuncSample8.pdf
	lyxscale 40
	width 30text%
	subcaption

\end_inset 


\layout Caption

(a) bias kernel with 
\begin_inset Formula $\alpha=1$
\end_inset 

 and (b) Summed combination of: RBF kernel, 
\begin_inset Formula $\alpha=1$
\end_inset 

, 
\begin_inset Formula $\gamma=10$
\end_inset 

; bias kernel, 
\begin_inset Formula $\alpha=$
\end_inset 

1; and white noise kernel, 
\begin_inset Formula $\beta=100$
\end_inset 

.
 Samples can be recreated with the script 
\family typewriter 
demCovFuncSample
\family default 
.
 
\begin_inset LatexCommand \label{cap:kernelSamples}

\end_inset 


\end_inset 


\layout EndFrame

\layout BeginFrame

Consistency
\layout Itemize

Predictions remain the same regardless of the number and location of the
 test points.
\begin_inset Formula \[
p\left(\mathbf{f}_{*}|\mathbf{f}\right)=\int p\left(\mathbf{f}_{*},\mathbf{f}_{+}|\mathbf{f}\right)d\mathbf{f}_{+},\]

\end_inset 


\layout Itemize

For the system to be consistent this conditional probability must be independent
 of the length of 
\begin_inset Formula $\mathbf{f}_{+}$
\end_inset 

.
 
\layout Itemize

In other words.
\begin_inset Formula \[
p\left(\mathbf{f}_{*}|\mathbf{f}\right)=\int p\left(\mathbf{f}_{*},\mathbf{f}_{+}|\mathbf{f}\right)d\mathbf{f}_{+}=\int p\left(\mathbf{f}_{*},\hat{\mathbf{f}}_{+}|\mathbf{f}\right)d\hat{\mathbf{f}}_{+}\]

\end_inset 


\layout EndFrame

\layout BeginFrame

The GP-LVM
\begin_inset LatexCommand \label{sec:GPLVM}

\end_inset 


\layout Itemize

Probabilistic PCA uses Gaussian likelihood, 
\begin_inset Formula \[
p\left(\mathbf{Y}|\mathbf{W},\mathbf{X},\beta\right)=\prod_{n=1}^{N}N\left(\mathbf{y}_{n}|\mathbf{Wx}_{n},\beta^{-1}\mathbf{I}\right)\]

\end_inset 

with a Gaussian prior on the latent variables, 
\begin_inset Formula $\mathbf{X}$
\end_inset 

.
 
\layout Itemize

GP-LVM: a different perspective on latent variable models.
\begin_deeper 
\layout Itemize

Rather than marginalising the latent variables
\layout Itemize

We seek to marginalise the mapping.
 
\end_deeper 
\layout EndFrame

\layout BeginFrame

Probabilistic PCA vs GP-LVM
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard


\begin_inset Graphics
	filename ./diagrams/ppcaGraph.pdf
	width 45text%
	subcaption
	subcaptionText "Standard Probabilistic PCA"

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/gplvmGraph.pdf
	width 45text%
	subcaption
	subcaptionText "GP-LVM model representation"

\end_inset 


\end_inset 


\layout EndFrame

\layout BeginFrame

Linear Mappings and PPCA
\layout Itemize

If mappings are constrained linear
\begin_deeper 
\layout Itemize

dual representation of probabilistic PCA.
 
\end_deeper 
\layout Itemize

The required marginalisation now takes the form
\begin_inset Formula \[
p\left(\mathbf{Y}|\mathbf{X},\beta\right)=\int\prod_{n=1}^{N}p\left(\mathbf{y}_{n}|\mathbf{x}_{n},\mathbf{W},\beta\right)p\left(\mathbf{W}\right)d\mathbf{W}.\]

\end_inset 


\layout Itemize

Using Gaussian prior distribution 
\begin_inset Formula \[
p\left(\mathbf{W}\right)=\prod_{i}N\left(\mathbf{w}_{i}|\mathbf{0},\mathbf{I}\right),\]

\end_inset 

 
\begin_inset Formula $\mathbf{w}_{i}$
\end_inset 

 is 
\begin_inset Formula $i$
\end_inset 

th row of 
\begin_inset Formula $\mathbf{W}$
\end_inset 

.
 
\layout EndFrame

\layout BeginFrame

Marginal Likelihood
\layout Itemize

The marginal likelihood is then found as
\begin_inset Formula \begin{equation}
p\left(\mathbf{Y}|\mathbf{X},\beta\right)=\frac{1}{\left(2\pi\right)^{\frac{DN}{2}}\left|\mathbf{K}\right|^{\frac{D}{2}}}\exp\left(-\frac{1}{2}\textrm{tr}\left(\mathbf{K}^{-1}\mathbf{YY}^{\textrm{T}}\right)\right),\label{eq:appDualPPCAMarginal}\end{equation}

\end_inset 

where 
\begin_inset Formula $\mathbf{K}=\mathbf{XX}^{\textrm{T}}+\beta^{-1}\mathbf{I}$
\end_inset 

 and 
\begin_inset Formula $\mathbf{X}=\left[\mathbf{x}_{1}^{\textrm{T}}\dots\mathbf{x}_{N}^{\textrm{T}}\right]^{\textrm{T}}$
\end_inset 

.
 
\layout EndFrame

\layout BeginFrame

Duality
\layout Itemize

Note that by taking 
\begin_inset Formula $\mathbf{C}=\mathbf{W}\mathbf{W}^{\textrm{T}}+\beta^{-1}\mathbf{I}$
\end_inset 

 we express PPCA likelihood as
\begin_inset Formula \[
p\left(\mathbf{Y}|\mathbf{W},\beta\right)=\frac{1}{\left(2\pi\right)^{\frac{DN}{2}}\left|\mathbf{C}\right|^{\frac{N}{2}}}\exp\left(-\frac{1}{2}\textrm{tr}\left(\mathbf{C}^{-1}\mathbf{Y}^{\textrm{T}}\mathbf{Y}\right)\right),\]

\end_inset 


\layout Itemize

Compare with our new model
\begin_inset Formula \[
p\left(\mathbf{Y}|\mathbf{X},\beta\right)=\frac{1}{\left(2\pi\right)^{\frac{DN}{2}}\left|\mathbf{K}\right|^{\frac{D}{2}}}\exp\left(-\frac{1}{2}\textrm{tr}\left(\mathbf{K}^{-1}\mathbf{YY}^{\textrm{T}}\right)\right),\]

\end_inset 

where 
\begin_inset Formula $\mathbf{K}=\mathbf{XX}^{\textrm{T}}+\beta^{-1}\mathbf{I}$
\end_inset 

.
\layout EndFrame

\layout BeginFrame

GP-LVM Graph
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./diagrams/gpGraphGPLVM.pdf
	width 35text%

\end_inset 


\layout Caption

The Gaussian process as a latent variable model, now both kernel parameters,
 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset 

and latent positions are optimised.
 
\begin_inset LatexCommand \label{cap:gplvmGraph}

\end_inset 


\end_inset 


\layout EndFrame

\layout BeginFrame

Gaussian Process
\layout Itemize

Optimisation of the new marginal is clearly related to optimisation of the
 previous likelihood.
\layout Itemize

New likelihood is of the form
\begin_inset Formula \begin{equation}
p\left(\mathbf{Y}|\mathbf{X},\beta\right)=\prod_{i=1}^{D}\frac{1}{\left(2\pi\right)^{\frac{N}{2}}\left|\mathbf{K}\right|^{\frac{1}{2}}}\exp\left(-\frac{1}{2}\mathbf{y}_{:,i}^{\textrm{T}}\mathbf{K}^{-1}\mathbf{y}_{:,i}\right),\label{eq:gplvmLikelihood}\end{equation}

\end_inset 

where 
\begin_inset Formula $\mathbf{y}_{:,i}$
\end_inset 

 is the 
\begin_inset Formula $i$
\end_inset 

th column of 
\begin_inset Formula $\mathbf{Y}$
\end_inset 

.
 
\layout Itemize

This is recognised as a product of 
\begin_inset Formula $D$
\end_inset 

 independent Gaussian processes.
\layout EndFrame

\layout BeginFrame

Maximisation of the Marginal Likelihood
\layout Itemize

Proof of optimum is the dual of the proof given in 
\begin_inset LatexCommand \citet{Tipping:probpca99}

\end_inset 

.
\layout Itemize

Maximising log likelihood is equivalent to minimising 
\begin_inset Formula \begin{equation}
L=\frac{N}{2}\ln2\pi+\frac{1}{2}\ln\left|\mathbf{K}\right|+\frac{1}{2}\textrm{tr}\left(\mathbf{K}^{-1}\mathbf{S}\right),\label{eq:negEigObjective}\end{equation}

\end_inset 

where 
\begin_inset Formula $\mathbf{S}=D^{-1}\mathbf{Y}\mathbf{Y}^{\textrm{T}}$
\end_inset 

.
 
\layout Itemize

Gradient of the likelihood wrt 
\begin_inset Formula $\mathbf{X}$
\end_inset 

 is
\begin_inset Formula \[
\frac{\partial L}{\partial\mathbf{X}}=-\mathbf{K}^{-1}\mathbf{S}\mathbf{K}^{-1}\mathbf{X}+\mathbf{K}^{-1}\mathbf{X},\]

\end_inset 

setting the equation to zero and pre-multiplying by 
\begin_inset Formula $\mathbf{K}$
\end_inset 

 gives
\begin_inset Formula \[
\mathbf{S}\left[\beta^{-1}\mathbf{I}+\mathbf{XX}^{\textrm{T}}\right]^{-1}\mathbf{X}=\mathbf{X}.\]

\end_inset 


\layout EndFrame

\layout BeginFrame

Singular Value Decomposition
\layout Itemize

Substitute 
\begin_inset Formula $\mathbf{X}$
\end_inset 

 with its SVD, 
\begin_inset Formula $\mathbf{X}=\mathbf{ULV}^{\textrm{T}}$
\end_inset 

, giving
\begin_inset Formula \[
\mathbf{SU}\left[\mathbf{L}+\beta^{-1}\mathbf{L}^{-1}\right]^{-1}\mathbf{V}^{\textrm{T}}=\mathbf{U}\mathbf{LV}^{\textrm{T}}\]

\end_inset 


\layout Itemize

Right multiplying both sides by 
\begin_inset Formula $\mathbf{V}$
\end_inset 

 giving
\begin_inset Formula \[
\mathbf{SU}=\mathbf{U}\left(\beta^{-1}\mathbf{I}+\mathbf{L}^{2}\right),\]

\end_inset 


\layout Itemize

Since 
\begin_inset Formula $\left(\beta^{-1}\mathbf{I}+\mathbf{L}^{2}\right)$
\end_inset 

 is diagonal, this is an eigenvalue problem.
\layout Itemize


\begin_inset Formula $\mathbf{U}$
\end_inset 

 are eigenvectors of 
\begin_inset Formula $\mathbf{S}$
\end_inset 

 and 
\begin_inset Formula $\Lambda=\left(\beta^{-1}\mathbf{I}+\mathbf{L}^{2}\right)$
\end_inset 

 are the eigenvalues.
 
\layout Itemize

Thus elements from diagonal of 
\begin_inset Formula $\mathbf{L}$
\end_inset 

 are 
\begin_inset Formula \[
l_{i}=\left(\lambda_{i}-\beta^{-1}\right)^{\frac{1}{2}}.\]

\end_inset 

 
\layout EndFrame

\layout BeginFrame

The Retained Eigenvalues
\layout Itemize

If 
\begin_inset Formula $q<D$
\end_inset 

 need to select which eigenvectors to retain.
\layout Itemize

All eigenvectors are associated with stationary points.
\layout Itemize

Can rewrite objective as a difference of geometric and arithmetic mean.
\begin_deeper 
\layout Itemize

This implies eigenvalues must be neighbouring.
\end_deeper 
\layout Itemize

Solution for 
\begin_inset Formula $\beta$
\end_inset 

 becomes negative if largest eigenvalues aren't retained.
\layout EndFrame

\layout BeginFrame

Equivalence of Eigenvalue Problems
\begin_inset LatexCommand \label{sec:equivEigenvalue}

\end_inset 


\layout Itemize

For DPPCA the eigenvalue problem is of the form
\begin_inset Formula \[
\mathbf{YY}^{\textrm{T}}\mathbf{U}=\mathbf{U}\Lambda.\]

\end_inset 

Premultiplying by 
\begin_inset Formula $\mathbf{Y}^{\textrm{T}}$
\end_inset 

 gives 
\begin_inset Formula \begin{equation}
\mathbf{Y}^{\textrm{T}}\mathbf{YY}^{\textrm{T}}\mathbf{U}=\mathbf{Y}^{\textrm{T}}\mathbf{U}\Lambda\label{eq:covarianceEigenProblem}\end{equation}

\end_inset 


\layout Itemize


\begin_inset Formula $\mathbf{U}$
\end_inset 

 are the eigenvectors of 
\begin_inset Formula $\mathbf{Y}\mathbf{Y}^{\textrm{T}}$
\end_inset 

 so 
\begin_inset Formula $\mathbf{U}^{\textrm{T}}\mathbf{YY}^{\textrm{T}}\mathbf{U}=\Lambda$
\end_inset 

, 
\begin_deeper 
\layout Itemize

Matrix 
\begin_inset Formula $\mathbf{U}^{\prime}=\mathbf{Y}^{\textrm{T}}\mathbf{U}\Lambda^{-\frac{1}{2}}$
\end_inset 

 is orthonormal.
 
\end_deeper 
\layout Itemize

Post multiplying both sides of (
\begin_inset LatexCommand \ref{eq:covarianceEigenProblem}

\end_inset 

) by 
\begin_inset Formula $\Lambda^{-\frac{1}{2}}$
\end_inset 

 gives
\begin_inset Formula \[
\mathbf{Y}^{\textrm{T}}\mathbf{YU}^{\prime}=\mathbf{U}^{\prime}\Lambda\]

\end_inset 

which is the form of the eigenvalue problem associated with PPCA.
\layout EndFrame

\layout BeginFrame

Non-linear GP-LVM
\begin_inset LatexCommand \label{sec:GP-LVMalgorithmic}

\end_inset 


\layout Itemize

PCA can be interpreted as a product of linear Gaussian processes.
\layout Itemize

Can replace the linear kernel and obtain non-linear latent variable models.
\layout Itemize

Can no-longer use an eigenvalue problem to solve.
\layout EndFrame

\layout BeginFrame

Optimisation of the Non-linear Model
\layout Itemize

No closed form solution for non-linear model.
\layout Itemize

Gradients of kernel required
\begin_inset Formula \begin{equation}
\frac{\partial L}{\partial\mathbf{K}}=\mathbf{K}^{-1}\mathbf{YY}^{\textrm{T}}\mathbf{K}^{-1}-D\mathbf{K}^{-1},\label{eq:likelihoodGradK}\end{equation}

\end_inset 

And combined with 
\begin_inset Formula $\frac{\partial\mathbf{K}}{\partial x_{n,j}}$
\end_inset 

 via chain rule.
 
\layout EndFrame

\layout BeginFrame

Illustration of GP-LVM via SCG
\begin_inset LatexCommand \label{sub:IllustrationGP-LVM}

\end_inset 


\layout Itemize

Oil Data 
\begin_deeper 
\layout Itemize

Twelve dimensional data set.
\layout Itemize

Oil flow in a pipeline.
\layout Itemize

Stratified, annular and homogeneous.
\end_deeper 
\layout EndFrame

\layout BeginFrame

Oil Data Contd
\layout Itemize

Compare GP-LVM with MDS methods.
\layout Itemize

Use RBF kernel for GP-LVM
\begin_inset Formula \[
k\left(\mathbf{x}_{i},\mathbf{x}_{j}\right)=\alpha_{\textrm{rbf}}\exp\left(-\frac{\gamma}{2}\left(\mathbf{x}_{i}-\mathbf{x}_{j}\right)^{\textrm{T}}\left(\mathbf{x}_{i}-\mathbf{x}_{j}\right)\right)+\alpha_{\textrm{bias}}+\beta^{-1}\delta_{ij}.\]

\end_inset 

optimise jointly with respect to 
\begin_inset Formula $\mathbf{X}$
\end_inset 

, 
\begin_inset Formula $\alpha_{\textrm{bias}},\,\alpha_{\textrm{rbf}}$
\end_inset 

, 
\begin_inset Formula $\beta$
\end_inset 

 and 
\begin_inset Formula $\gamma$
\end_inset 

.
 
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./diagrams/pcaOil100.pdf
	lyxscale 70
	width 30text%
	keepAspectRatio
	subcaption
	subcaptionText "PCA"

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/gplvmOil100.pdf
	lyxscale 70
	width 30text%
	keepAspectRatio
	subcaption
	subcaptionText "GP-LVM"

\end_inset 


\hfill 
 
\begin_inset Graphics
	filename ./diagrams/nonmetricMdsOil100.pdf
	lyxscale 70
	width 30text%
	keepAspectRatio
	subcaption
	subcaptionText "Non-metric MDS"

\end_inset 


\newline 

\begin_inset Graphics
	filename ./diagrams/sammonOil100.pdf
	lyxscale 70
	width 30text%
	keepAspectRatio
	subcaption
	subcaptionText "Metric MDS"

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/gtmOil100.pdf
	lyxscale 70
	width 30text%
	keepAspectRatio
	subcaption
	subcaptionText "GTM"

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/kpcaOil100.pdf
	lyxscale 70
	width 30text%
	keepAspectRatio
	subcaption
	subcaptionText "kernel PCA"

\end_inset 


\newline 

\end_inset 


\layout EndFrame

\layout BeginFrame

Nearest Neighbour Errors
\layout Standard


\begin_inset Float table
wide false
collapsed false

\layout Standard
\align center 

\begin_inset ERT
status Collapsed

\layout Standard

\backslash 
small 
\end_inset 


\begin_inset  Tabular
<lyxtabular version="3" rows="2" columns="7">
<features>
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Method
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

PCA
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

GP-LVM
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Non-metric MDS
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Metric MDS
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

GTM*
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

kernel PCA*
\end_inset 
</cell>
</row>
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Errors
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

20
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

4
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

13
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

6
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

7
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

13
\end_inset 
</cell>
</row>
</lyxtabular>

\end_inset 


\layout Caption

Errors made by the different methods when using the latent-space for nearest
 neighbour classification in the latent space.
 Both the GTM and kernel PCA are given asterisks as the result shown is
 the best obtained for each method from a range of different parameterisations.
\begin_inset LatexCommand \label{cap:oil100NNErrors}

\end_inset 


\end_inset 

 
\layout EndFrame

\layout BeginFrame

Visualising the Uncertainty
\begin_inset LatexCommand \label{sub:visualisingUncertainty}

\end_inset 


\layout Itemize

Likelihood (
\begin_inset LatexCommand \ref{eq:gplvmLikelihood}

\end_inset 

) a product of 
\begin_inset Formula $D$
\end_inset 

 separate Gaussian processes.
 
\layout Itemize

We have maintained the implicit assumption in PCA that 
\emph on 
a priori 
\emph default 
each dimension is identically distributed.
\layout Itemize

This leads to an 
\emph on 
a posteriori
\emph default 
 shared level of uncertainty in each process.
 
\layout Itemize

This allows us to visualise the uncertainty in the latent space.
\layout Itemize

The uncertainty is visualised by varying the intensity of the background
 pixels.
 
\layout EndFrame

\layout BeginFrame

Computational Complexity
\layout Itemize

Each gradient step requires an inverse of the kernel matrix.
\layout Itemize

This is an 
\begin_inset Formula $O\left(N^{3}\right)$
\end_inset 

 operation.
\layout Itemize

Renders the algorithm impractical for many data sets of interest.
 
\layout Itemize

Seek to maximise a sparse approximation to the full likelihood.
\layout EndFrame

\layout BeginFrame

Large Data Sets
\layout Itemize

In 
\begin_inset LatexCommand \citet{Lawrence:gplvm03,Lawrence:pnpca05}

\end_inset 

 a sub-set of data approach is suggested.
\layout Itemize

This approach has two main drawbacks:
\begin_deeper 
\layout Itemize

It suffers from the lack of a convergence criterion.
\layout Itemize

It discards information in the data set.
 
\end_deeper 
\layout Itemize

A more promising approach is suggested in 
\begin_inset LatexCommand \citet{Snelson:pseudo05}

\end_inset 

 and developed in 
\begin_inset LatexCommand \citet{Quinonero:unifying05}

\end_inset 

.
\layout Itemize

This approach is now available in the FGPLVM toolbox and documented in 
\begin_inset LatexCommand \citep[in preparation]{Lawrence:largescale06}

\end_inset 

.
\layout EndFrame

\layout BeginFrame

Sub-set of Data 
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./diagrams/trOil1.pdf
	lyxscale 50
	width 50text%
	keepAspectRatio

\end_inset 

 
\layout Caption

The full oil flow data set visualised with an RBF based kernel using sub-set
 of data approximations.
\begin_inset LatexCommand \label{cap:gplvmOilVisualise}

\end_inset 


\end_inset 


\layout EndFrame

\layout BeginFrame

Full GP-LVM
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./diagrams/fullGplvmOil1000.pdf
	lyxscale 50
	width 50text%
	keepAspectRatio

\end_inset 


\layout Caption

The full GP-LVM algorithm with RBF kernel on the oil flow data (uses the
 GPLVMCPP toolbox).
 
\begin_inset LatexCommand \label{cap:fullOil}

\end_inset 


\end_inset 


\layout EndFrame

\layout BeginFrame

Nearest Neighbour in 
\begin_inset Formula $\mathbf{X}$
\end_inset 


\layout Standard


\begin_inset Float table
wide false
collapsed false

\layout Standard
\align center 

\begin_inset  Tabular
<lyxtabular version="3" rows="2" columns="6">
<features>
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<column alignment="center" valignment="top" rightline="true" width="0">
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Model
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

PCA
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Sparse GP-LVM (IVM)
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

GP-LVM (RBF)
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

GTM
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

Y
\end_inset 
</cell>
</row>
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Errors
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

162
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

24
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

1
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

11
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

2
\end_inset 
</cell>
</row>
</lyxtabular>

\end_inset 


\layout Caption

Number of errors for nearest neighbour classification in the latent-space
 for the full oil data set (1000 points).
 Far right column contains result for nearest neighbour in the data space,
 also presented is a result for the GTM algorithm.
\begin_inset LatexCommand \label{cap:oilClassiificationTable}

\end_inset 


\end_inset 


\layout EndFrame

\layout BeginFrame

Back Constraints
\layout Itemize

Joint work with Joaquin Quino
\begin_inset ERT
status Collapsed

\layout Standard

\backslash 
~{n}
\end_inset 

ero Candela
\layout Itemize

GP-LVM provides a smooth mapping from latent space to the data space.
 
\layout Itemize

Points close in latent space will be close in data space.
 
\layout Itemize

Does not imply that points which are close in data space will be close in
 latent space.
\layout Itemize

In recent work 
\begin_inset LatexCommand \citep[in preparation]{Lawrence:backconstraints06}

\end_inset 

 use of back constraints is suggested.
 
\layout EndFrame

\layout BeginFrame

Back Constraints II
\layout Itemize

Back constraints constrain latent points to be a smooth function of data
 points.
\begin_inset Formula \[
x_{n,i}=f_{i}\left(\mathbf{y}_{n},\mathbf{a}_{i}\right)\]

\end_inset 

where 
\begin_inset Formula $\mathbf{w}$
\end_inset 

 are parameters.
\layout Itemize

Instead of maximising wrt 
\begin_inset Formula $\mathbf{X}$
\end_inset 

, maximise wrt 
\begin_inset Formula $\mathbf{A}=\left[\mathbf{a}_{1},\dots,\mathbf{a}_{q}\right]^{\textrm{T}}.$
\end_inset 


\layout Itemize

This forces points which are close in data space to be close in latent space.
 
\layout EndFrame

\layout BeginFrame

Motion Capture Data
\layout Itemize

Motion capture of a man running.
\layout Itemize

Subject breaking into a run from standing.
 
\layout Itemize

Approximately three full strides in the sequence.
 
\layout Itemize

Data is mean subtracted so subject runs `in place'.
 
\begin_deeper 
\layout Itemize

The data is therefore somewhat periodic in nature.
\layout Itemize

Angle of run changes during sequence.
\end_deeper 
\layout Itemize

Compare pure GP-LVM with GP-LVM with back constraints.
 
\layout Itemize

The back constraint was implemented through an RBF based kernel mapping
 with 
\begin_inset Formula $\gamma=1\times10^{-3}$
\end_inset 

.
 
\layout EndFrame

\layout BeginFrame

Running Man
\layout Standard


\begin_inset Float figure
wide true
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./diagrams/demStick1Connected.pdf
	lyxscale 50
	width 45text%
	subcaption
	subcaptionText "Pure GP-LVM $L=1,543$"

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/demStick3Connected.pdf
	lyxscale 50
	width 45text%
	subcaption
	subcaptionText "Back constraints $L=1,000$"

\end_inset 


\layout Caption

\SpecialChar ~

\end_inset 


\layout EndFrame

\layout BeginFrame

Running Man
\layout Itemize

The likelihood of the pure model is higher.
\layout Itemize

However the sequence is split across sub-sequences.
\layout Itemize

A circular structure is necessary for periodic nature of data.
\layout Itemize

Squashed spiral has either
\begin_deeper 
\layout Itemize

less representational power in the inner rings (inner groove distortion)
 in gramophone records)
\layout Itemize

or will crosses over itself (not consistent with data).
\end_deeper 
\layout Itemize

Note: using a three dimensional latent space alleviates the problem.
\layout EndFrame

\layout BeginFrame

Run Angle
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./diagrams/demStick3AngleLatent.pdf
	lyxscale 50
	width 35text%

\end_inset 


\newline 

\begin_inset Minipage
position 1
inner_position 0
height "0pt"
width "100col%"
collapsed false

\layout Standard


\begin_inset Graphics
	filename ./diagrams/demStick3Angle1.pdf
	lyxscale 40
	height 1in
	keepAspectRatio
	subcaption

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/demStick3Angle2.pdf
	lyxscale 40
	height 1in
	keepAspectRatio
	subcaption

\end_inset 


\hfill 
 
\begin_inset Graphics
	filename ./diagrams/demStick3Angle3.pdf
	lyxscale 40
	height 1in
	keepAspectRatio
	subcaption

\end_inset 


\hfill 
 
\begin_inset Graphics
	filename ./diagrams/demStick3Angle4.pdf
	lyxscale 40
	height 1in
	keepAspectRatio
	subcaption

\end_inset 


\end_inset 


\layout Caption

\SpecialChar ~

\end_inset 


\layout EndFrame

\layout BeginFrame

Vowel Data
\layout Itemize

Single speaker vowel data set (collaboration with Jon Malkin and Jeff Bilmes).
\layout Itemize

Cepstral coefficients and deltas of ten different vowel phonemes.
\layout Itemize

Data acquired as part of a vocal joystick system 
\begin_inset LatexCommand \cite{Bilmes:vocal06}

\end_inset 

.
 
\layout Itemize

PCA fails to separate the vowels.
\layout Itemize

PCA initialised GP-LVM therefore fragments the vowels.
\layout Itemize

Back constraints fix this.
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./diagrams/demVowels2.pdf
	lyxscale 50
	width 50text%
	keepAspectRatio
	subcaptionText "Pure GP-LVM"

\end_inset 


\layout Caption


\begin_inset ERT
status Collapsed

\layout Standard

\backslash 
small 
\end_inset 

Pure GP-LVM
\emph on 
.
 /a/
\emph default 
 red cross 
\emph on 
/ae/
\emph default 
 green circle 
\emph on 
/ao/
\emph default 
 blue plus 
\emph on 
/e/
\emph default 
 cyan asterix 
\emph on 
/i/
\emph default 
 magenta square 
\emph on 
/ibar/
\emph default 
 yellow diamond 
\emph on 
/o/
\emph default 
 red down triangle 
\emph on 
/schwa/
\emph default 
 green up triangle and 
\emph on 
/u/
\emph default 
 blue left triangle.
\begin_inset LatexCommand \label{cap:vowelsBack}

\end_inset 


\end_inset 


\layout EndFrame

\layout BeginFrame

\SpecialChar ~

\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./diagrams/demVowels3.pdf
	lyxscale 50
	width 50text%
	keepAspectRatio
	subcaptionText "Back Constraints"

\end_inset 


\layout Caption


\begin_inset ERT
status Collapsed

\layout Standard

\backslash 
small 
\end_inset 

 Back constrained
\emph on 
.
 /a/
\emph default 
 red cross 
\emph on 
/ae/
\emph default 
 green circle 
\emph on 
/ao/
\emph default 
 blue plus 
\emph on 
/e/
\emph default 
 cyan asterix 
\emph on 
/i/
\emph default 
 magenta square 
\emph on 
/ibar/
\emph default 
 yellow diamond 
\emph on 
/o/
\emph default 
 red down triangle 
\emph on 
/schwa/
\emph default 
 green up triangle and 
\emph on 
/u/
\emph default 
 blue left triangle.
\end_inset 


\layout EndFrame

\layout BeginFrame

GP-LVM with Dynamics
\layout Itemize

Recently 
\begin_inset LatexCommand \citet{Wang:gpdm05}

\end_inset 

 described an approach to adding dynamics to the GP-LVM.
 
\layout Itemize

Assume data is presented in temporal order.
\layout Itemize

Place a Markov chain distribution over the latent space by defining 
\begin_inset Formula $p\left(\mathbf{x}_{n}|\mathbf{x}_{n-1}\right)$
\end_inset 

.
\layout Itemize

Leads to a prior distribution 
\begin_inset Formula $p\left(\mathbf{X}\right)=p\left(\mathbf{x}_{1}\right)\prod_{n=2}^{N}p\left(\mathbf{x}_{n}|\mathbf{x}_{n-1}\right)$
\end_inset 

.
 
\layout Itemize

Marginalising 
\begin_inset Formula $\mathbf{X}$
\end_inset 

 is now intractable.
\layout EndFrame

\layout BeginFrame

MAP Solution
\layout Itemize

It is straightforward to obtain maximum 
\emph on 
a posteriori 
\emph default 
(MAP) estimates of the solution.
 
\layout Itemize

In 
\begin_inset LatexCommand \citet{Wang:gpdm05}

\end_inset 

 using a Gaussian process to relate 
\begin_inset Formula $\mathbf{x}_{n}$
\end_inset 

 to 
\begin_inset Formula $\mathbf{x}_{n-1}$
\end_inset 

 is suggested.
\layout Itemize

Joint likelihood is then given by
\begin_inset ERT
status Collapsed

\layout Standard

\backslash 
tiny 
\end_inset 


\begin_inset Formula \begin{eqnarray*}
p\left(\mathbf{Y},\mathbf{X}\right) & = & -\frac{DN}{2}\log2\pi-\frac{D}{2}\log\left|\mathbf{K}\right|-\frac{1}{2}\textrm{tr}\left(\mathbf{K}^{-1}\mathbf{Y}\mathbf{Y}^{\textrm{T}}\right)\\
 &  & -\frac{qN}{2}\log2\pi-\frac{q}{2}\log\left|\mathbf{K}_{x}\right|-\frac{1}{2}\textrm{tr}\left(\mathbf{K}_{x}^{-1}\left(\hat{\mathbf{X}}-\mathbf{\tilde{\mathbf{X}}}\right)\left(\hat{\mathbf{X}}-\mathbf{\tilde{\mathbf{X}}}\right)^{\textrm{T}}\right),\end{eqnarray*}

\end_inset 


\begin_inset ERT
status Collapsed

\layout Standard

\backslash 
normalsize 
\end_inset 

where 
\begin_inset Formula $\mathbf{\hat{X}}=\left[\mathbf{x}_{2}\dots\mathbf{x}_{N}\right]^{\textrm{T}}$
\end_inset 

 and 
\begin_inset Formula $\tilde{\mathbf{X}}=\left[\mathbf{x}_{1}\dots\mathbf{x}_{N-1}\right]^{\textrm{T}}$
\end_inset 

 .
\layout Itemize


\begin_inset Formula $\mathbf{K}_{x}$
\end_inset 

 is the dynamics covariance function, constructed on 
\begin_inset Formula $\tilde{\mathbf{X}}$
\end_inset 

.
 
\layout EndFrame

\layout BeginFrame

Implementation
\layout Itemize

For dynamics, use an RBF kernel and a white noise term,
\size small 

\begin_inset Formula \begin{eqnarray*}
k\left(\mathbf{x}_{n},\mathbf{x}_{m}\right) & = & \alpha_{\textrm{rbf}}^{\prime}\exp\left(-\frac{\gamma^{\prime}}{2}\left(\mathbf{x}_{n}-\mathbf{x}_{m}\right)^{\textrm{T}}\left(\mathbf{x}_{n}-\mathbf{x}_{m}\right)\right)\\
 &  & +\beta^{\prime-1}\delta_{nm}.\end{eqnarray*}

\end_inset 


\size default 

\begin_inset Formula $\delta_{nm}$
\end_inset 

 is the Kronecker delta function.
\layout Itemize

Can fix the dynamics model parameters by hand.
 
\layout Itemize

The signal variance is given by 
\begin_inset Formula $\alpha_{\textrm{rbf}}^{\prime}$
\end_inset 

 and the noise variance by 
\begin_inset Formula $\beta^{\prime-1}$
\end_inset 

, 
\layout Itemize


\begin_inset Formula $\gamma$
\end_inset 

 controls the smoothness.
\layout Itemize

We now show some samples from dynamics covariances.
\layout EndFrame

\layout BeginFrame

Dynamics Samples I
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./diagrams/dynSample11.pdf
	lyxscale 50
	width 30text%
	subcaption
	subcaptionText "$ \gamma^{\prime}=0.2, \beta^{\prime-1}=4\times10^{-4}$"

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/dynSample21.pdf
	lyxscale 50
	width 30text%
	subcaption
	subcaptionText "$ \gamma^{\prime}=1, \beta^{\prime}=4\times10^{-4}$"

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/dynSample31.pdf
	lyxscale 50
	width 30text%
	subcaption
	subcaptionText " $\gamma^{\prime}=5, \beta^{\prime-1}=4\times10^{-4}$"

\end_inset 


\layout Caption


\begin_inset Formula $\alpha_{\textrm{rbf}}^{\prime}=0.1$
\end_inset 


\end_inset 


\layout EndFrame

\layout BeginFrame

Dynamics Samples II
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard


\begin_inset Graphics
	filename ./diagrams/dynSample12.pdf
	lyxscale 50
	width 30text%
	subcaption
	subcaptionText "$\gamma^{\prime}=0.2, \beta^{\prime-1}=1\times10^{-6}$"

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/dynSample22.pdf
	lyxscale 50
	width 30text%
	subcaption
	subcaptionText "$\gamma^{\prime}=1, \beta^{\prime-1}=1\times10^{-6}$"

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/dynSample32.pdf
	lyxscale 50
	width 30text%
	subcaption
	subcaptionText "$\gamma^{\prime}=5, \beta^{\prime-1}=4\times10^{-6}$"

\end_inset 


\layout Caption


\begin_inset Formula $\alpha_{\textrm{rbf}}^{\prime}=0.1$
\end_inset 


\end_inset 


\layout EndFrame

\layout BeginFrame

Running Man + Dynamics
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./diagrams/demStick2Connected.pdf
	lyxscale 50
	width 45text%

\end_inset 


\layout Caption

Using dynamics from previous slide (a) 
\begin_inset LatexCommand \label{cap:demStickManDynamics}

\end_inset 


\end_inset 


\layout EndFrame

\layout BeginFrame

Loop Closure in Robotics
\layout Itemize

On-going work with Dieter Fox and Brian Ferris at the University of Washington.
\layout Itemize

Robot navigation via wireless access points.
\layout Itemize

Robot completes one loop ...
 space is inherently 2d.
\layout EndFrame

\layout BeginFrame

Loop Closure
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align block 

\begin_inset Graphics
	filename ./diagrams/demRobotWireless1.pdf
	lyxscale 50
	width 40text%
	subcaption
	subcaptionText "Pure GP-LVM"

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/demRobotWireless2.pdf
	lyxscale 50
	width 40text%
	subcaption
	subcaptionText "Back Constraints"

\end_inset 


\end_inset 


\layout EndFrame

\layout BeginFrame

Loop Closure II
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard


\begin_inset Graphics
	filename ./diagrams/demRobotWireless3.pdf
	lyxscale 50
	width 40text%
	subcaption
	subcaptionText "Pure GP-LVM"

\end_inset 


\hfill 

\begin_inset Graphics
	filename ./diagrams/demRobotWireless4.pdf
	lyxscale 50
	width 40text%
	subcaption
	subcaptionText "Back Constraints"

\end_inset 


\end_inset 


\layout EndFrame

\layout BeginFrame

Conclusions
\layout Itemize

GP-LVM
\begin_deeper 
\layout Itemize

Probabilistic model: combines PPCA and GPs
\end_deeper 
\layout Itemize

Computational issues for larger data sets.
\begin_deeper 
\layout Itemize

Sub-set of data methods.
\layout Itemize

Code available for more advanced approaches.
\end_deeper 
\layout Itemize

Extensions - Dynamics
\begin_deeper 
\layout Itemize

Forces temporal continuity in latent space.
\layout Itemize

We advocated manual setting of kernel parameters & sampling.
\end_deeper 
\layout Itemize

Extension - Back Constraints
\begin_deeper 
\layout Itemize

Force local distance preservation.
\layout Itemize
\line_bottom 
Can be combined with back constraints.
\end_deeper 
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
small 
\end_inset 


\layout Standard


\begin_inset LatexCommand \BibTeX[abbrv]{lawrence,other,zbooks}

\end_inset 


\the_end

